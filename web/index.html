<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="author" content="Michael Hansen">
        <title>voice2json - Offline Speech/Intent Recognition for Linux</title>
        <link rel="icon" href="img/favicon.png">
        <link rel="stylesheet" href="css/fonts.css">
        <link rel="stylesheet" href="css/normalize.css">
        <link rel="stylesheet" href="css/milligram.min.css">
        <link rel="stylesheet" href="css/main.css">
    </head>
    <body>

        <main class="wrapper">

            <nav class="navigation">

                <section class="container">
                    <a class="navigation-title" href="/">
                        <img class="img" style="height: 3rem;" src="img/microphone.svg">
                        &nbsp;
                        <h1 class="title">voice2json</h1>
                    </a>
                    <ul class="navigation-list float-right">
                        <li class="navigation-item">
                            <a class="navigation-link" href="https://voice2json.readthedocs.io/">Documentation</a>
                        </li>
                        <li class="navigation-item">
                            <a class="navigation-link" href="https://github.com/synesthesiam/voice2json/releases">Download</a>
                        </li>
                    </ul>
                    <a href="https://github.com/synesthesiam/voice2json" title="voice2json on Github" target="_blank">
                        <svg class="octocat" viewBox="0 0 250 250"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path class="octocat-arm" d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"></path><path class="octocat-body" d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"></path></svg>
                    </a>
                </section>
            </nav>

            <section class="container" id="main">
                <img src="img/voice2json.svg" style="height: 10rem;">
                <p style="margin-top: 1rem;">
                    <strong>voice2json</strong> is a set of command-line tools for <strong>offline speech/intent recognition</strong> on Linux.
                    It is free, open source, and <a href="https://github.com/synesthesiam/voice2json-profiles">supports 15 languages</a>.
                </p>

                <img alt="voice2json translates voice commands to JSON events" title="voice2json overview" src="img/overview-1.svg" style="height: 20rem;">

                <hr>

                <p>
                    When you provide <tt>voice2json</tt> with a <a href="https://voice2json.readthedocs.io/en/latest/sentences/">description of your custom voice commands</a>:
                </p>
                <pre><code>[LightState]
states = (on | off)
turn (&lt;states&gt;){state} [the] light</code></pre>

                <p>
                    and then <a href="https://voice2json.readthedocs.io/en/latest/commands/#train-profile">train your profile</a>:
                </p>


                <pre><code>$ voice2json train-profile</code></pre>

                <p>
                    you can now recognize intents from audio data:
                </p>

                <pre><code>$ voice2json transcribe-wav < turn-on-the-light.wav | \
      voice2json recognize-intent | \
      jq .</code></pre>

                output is a <a href="https://voice2json.readthedocs.io/en/latest/formats/#intents">JSON event</a>:

                <pre><code>{
    "text": "turn on the light",
    "intent": {
        "name": "LightState"
    },
    "slots": {
        "state": "on"
    }
}</code></pre>

                <hr>

                <h3>voice2json is...</h3>
                <ul>
                    <li>Free and fully <a href="https://github.com/synesthesiam/voice2json">open source</a></li>
                    <li>Completely <strong>offline</strong>, no account or internet connection required, ever</li>
                    <li>Designed for use in <a href="https://voice2json.readthedocs.io/en/latest/commands/">Unix-style workflows</a> and shell scripts</li>
                    <li>Optimized for <a href="https://voice2json.readthedocs.io/en/latest/sentences/">custom voice commands</a> with <a href="https://voice2json.readthedocs.io/en/latest/commands/#pronounce-word">uncommon words</a></li>
                        <li>Quick to re-train, even for <a href="https://voice2json.readthedocs.io/en/latest/recipes/#set-and-run-timers">millions of possible voice commands</a></li>
                </ul>

                <h3>Available Commands</h3>
                <ul>
                    <li><a href="https://voice2json.readthedocs.io/en/latest/commands/#print-profile">print-profile</a> - Print profile settings</li>
                    <li><a href="https://voice2json.readthedocs.io/en/latest/commands/#train-profile">train-profile</a> - Generate speech/intent artifacts</li>
                    <li><a href="https://voice2json.readthedocs.io/en/latest/commands/#transcribe-wav">transcribe-wav</a> - Transcribe WAV file to text</li>
                    <li><a href="https://voice2json.readthedocs.io/en/latest/commands/#recognize-intent">recognize-intent</a> - Recognize intent from JSON or text</li>
                    <li><a href="https://voice2json.readthedocs.io/en/latest/commands/#wait-wake">wait-wake</a> - Listen to live audio stream for wake word</li>
                    <li><a href="https://voice2json.readthedocs.io/en/latest/commands/#record-command">record-command</a> - Record voice command from live audio stream</li>
                    <li><a href="https://voice2json.readthedocs.io/en/latest/commands/#pronounce-word">pronounce-word</a> - Look up or guess how a word is pronounced</li>
                    <li><a href="https://voice2json.readthedocs.io/en/latest/commands/#generate-examples">generate-examples</a> - Generate random intents</li>
                    <li><a href="https://voice2json.readthedocs.io/en/latest/commands/#record-examples">record-examples</a> - Generate and record speech examples</li>
                    <li><a href="https://voice2json.readthedocs.io/en/latest/commands/#test-examples">test-examples</a> - Test recorded speech examples</li>
                    <li><a href="https://voice2json.readthedocs.io/en/latest/commands/#tune-examples">tune-examples</a> - Tune acoustic model using recorded speech examplesrint profile settings</li>
                </ul>

                <hr>

                <h2>Getting Started</h2>

                <h3>Run with Docker</h3>
                <pre><code>docker run -d \
      -v "${HOME}:${HOME}" \
      -w "$(pwd)" \
      -u "$(id -u):$(id -g)" \
      voice2json/voice2json setup </code></pre>
            </section>

            <section class="container" id="contributing">
                <h5 class="title">Contributing</h5>
                <p>Want to contribute? Follow these <a href="https://github.com/synesthesiam/voice2json#contributing" title="Contributing">recommendations</a>.</p>
            </section>

            <footer class="footer">
                <section class="container">
                    <img src="img/terminal.svg">
                    <p>Created by <a target="_blank" href="https://synesthesiam.com" title="Michael Hansen">Michael Hansen</a>. Licensed under the <a target="_blank" href="https://github.com/synesthesiam/voice2json/blob/master/LICENSE" title="MIT License">MIT License</a>.</p>
                </section>
            </footer>

        </main>

        <script type="text/javascript" src="js/main.js"></script>
    </body>
</html>
